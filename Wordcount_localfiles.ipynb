{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSNRVeoixqYeI0D0jsrj2D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kousiknandy/pycolab/blob/main/Wordcount_localfiles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "m75VxiYbW2MG"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/kousiknandy/pycolab.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls -R pycolab"
      ],
      "metadata": {
        "id": "sWBbg-CxX269"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "uninteresting = {'the','and','i','of','to','my','a','in','that','was','me',\n",
        "    'with','but','had','you','he','which','it','as','not','his','for','by'}\n",
        "\n",
        "def read_lines(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        yield from f\n",
        "\n",
        "def read_words(line):\n",
        "    for l in line:\n",
        "        for words in re.finditer(r\"\\b\\w+\\b\", l, re.ASCII):\n",
        "            if (w := words.group(0).lower()) not in uninteresting:\n",
        "                yield w\n",
        "\n",
        "def mapper(filename):\n",
        "    wordcount = defaultdict(int)\n",
        "    lines = read_lines(filename)\n",
        "    words = read_words(lines)\n",
        "    for w in words:\n",
        "        wordcount[w] += 1\n",
        "    return wordcount\n"
      ],
      "metadata": {
        "id": "a-h_5X8-YJso"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wordhash(word):\n",
        "    h = 5381\n",
        "    for c in word:\n",
        "        h = h * 33 + ord(c)\n",
        "    return h\n",
        "\n",
        "def keypart():\n",
        "    words = defaultdict(list)\n",
        "    while w := (yield):\n",
        "        words[w[0]].append(w[1])\n",
        "    return words\n",
        ""
      ],
      "metadata": {
        "id": "wGC9VO3_to9d"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_summation(words):\n",
        "    try:\n",
        "        words.send(None)\n",
        "    except StopIteration as e:\n",
        "        count_list = e.value\n",
        "    res = {}\n",
        "    for k,v in count_list.items():\n",
        "        res[k] = sum(v)\n",
        "    return res\n",
        ""
      ],
      "metadata": {
        "id": "c3WCcburuyXC"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import glob\n",
        "\n",
        "parts = 2\n",
        "files = glob.iglob(\"pycolab/data/book/frankestine/*\")\n",
        "partitions = [keypart() for _ in range(parts)]\n",
        "for i in range(parts):\n",
        "    partitions[i].send(None)\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    res = executor.map(mapper, files)\n",
        "for wordc in res:\n",
        "    for w, c in wordc.items():\n",
        "        partitions[wordhash(w) % parts].send((w,c))\n",
        "with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "    res = executor.map(word_summation, partitions)\n",
        "ans = {}\n",
        "for wordc in res:\n",
        "    ans = {**ans, **wordc}\n"
      ],
      "metadata": {
        "id": "2I0U6zL7vyOR"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "freq = [(v,k) for k,v in ans.items()]\n",
        "topw = heapq.nlargest(25, freq)\n",
        "[t[1] for t in topw]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypgFnpeHy2MB",
        "outputId": "16546a2e-1d9b-44f0-cb96-47009ae56e3e"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['on',\n",
              " 'this',\n",
              " 'from',\n",
              " 'be',\n",
              " 'her',\n",
              " 'have',\n",
              " 'when',\n",
              " 'is',\n",
              " 'at',\n",
              " 'were',\n",
              " 'your',\n",
              " 'she',\n",
              " 'or',\n",
              " 'him',\n",
              " 'all',\n",
              " 'an',\n",
              " 'if',\n",
              " 'they',\n",
              " 'so',\n",
              " 'one',\n",
              " 'will',\n",
              " 'could',\n",
              " 'are',\n",
              " 'been',\n",
              " 'their']"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    }
  ]
}